# AI-Powered Video Transformation Pipeline

Transform videos using state-of-the-art AI models with an intuitive web interface. This project leverages Google Gemini and EachLabs APIs to provide intelligent video editing capabilities.

## ğŸš€ Features

- **Intelligent Frame Extraction**: Smart sampling of key video frames
- **AI-Powered Prompt Enhancement**: Automatic refinement of transformation prompts
- **Advanced Image Generation**: High-quality AI-generated transformations
- **Comprehensive Video Analysis**: Deep understanding of video content
- **Seamless Video Generation**: Smooth output video creation
- **Real-time Progress Tracking**: Monitor each step of the transformation
- **Web Interface**: User-friendly Flask-based application

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- FFmpeg installed on your system
- API Keys for:
  - OpenRouter (for Gemini access)
  - Google Gemini API
  - EachLabs API

## ğŸ› ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/ai-video-transformer.git
cd ai-video-transformer
```

### 2. Set Up Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables

Create a `.env` file in the root directory:

```env
OPENROUTER_API_KEY=your_openrouter_key
GEMINI_API_KEY=your_gemini_key
EACHLABS_API_KEY=your_eachlabs_key
```

## ğŸš€ Quick Start

### Option 1: Using the Web Interface

```bash
python src/api/app.py
```

Then open your browser and navigate to `http://localhost:5001`

### Option 2: Command Line Interface

```bash
python src/core/step5_with_auto_upload.py path/to/video.mp4 "your transformation prompt"
```

## ğŸ“ Project Structure

```
ai-video-transformer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                  # Core processing pipeline
â”‚   â”‚   â”œâ”€â”€ step1_frame_extraction.py
â”‚   â”‚   â”œâ”€â”€ step2_prompt_enhancement.py
â”‚   â”‚   â”œâ”€â”€ step3_single_output.py
â”‚   â”‚   â”œâ”€â”€ step4_single_output.py
â”‚   â”‚   â””â”€â”€ step5_with_auto_upload.py
â”‚   â”œâ”€â”€ api/                   # Flask API application
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â””â”€â”€ utils/                 # Utility modules
â”‚       â””â”€â”€ config.py
â”œâ”€â”€ tests/                     # Test suite
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ templates/                 # HTML templates
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ static/                    # Static assets
â”‚   â”œâ”€â”€ css/
â”‚   â””â”€â”€ js/
â”œâ”€â”€ docs/                      # Documentation
â”œâ”€â”€ examples/                  # Example scripts
â”œâ”€â”€ scripts/                   # Utility scripts
â”œâ”€â”€ uploads/                   # Uploaded videos
â”œâ”€â”€ jobs/                      # Job processing data
â”œâ”€â”€ temp/                      # Temporary processing files
â”œâ”€â”€ logs/                      # Application logs
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example              # Environment variables template
â”œâ”€â”€ .gitignore                # Git ignore rules
â”œâ”€â”€ LICENSE                   # License file
â””â”€â”€ README.md                 # This file
```

## ğŸ”§ Usage

### Web Interface

1. **Upload Video**: Drag and drop or browse to select your video (max 500MB)
2. **Enter Transformation**: Describe the desired changes
   - Example: "Make everyone wear sunglasses"
   - Example: "Change background to a tropical beach"
   - Example: "Convert to anime style"
3. **Process**: Click "Start Processing"
4. **Download**: Get your transformed video

### API Endpoints

- `GET /` - Main application interface
- `POST /api/process` - Start video processing
- `GET /api/status/<job_id>` - Check processing status
- `GET /api/results/<job_id>` - Get processing results
- `GET /api/file/<job_id>/<type>/<filename>` - Download files
- `DELETE /api/cancel/<job_id>` - Cancel processing
- `GET /api/health` - Health check

### Command Line

```bash
# Basic usage
python src/core/step5_with_auto_upload.py video.mp4 "transformation prompt"

# With custom output directory
python src/core/step5_with_auto_upload.py video.mp4 "prompt" --output-dir ./results

# Extract frames only
python src/core/step1_frame_extraction.py video.mp4 --num-frames 10
```

## ğŸ§ª Testing

Run the test suite:

```bash
python -m pytest tests/
```

Run a specific test:

```bash
python tests/test_pipeline.py
```

## ğŸ“Š Processing Pipeline

```mermaid
graph TD
    A[Video Input] --> B[Frame Extraction]
    B --> C[Prompt Enhancement]
    C --> D[Image Generation]
    D --> E[Video Analysis]
    E --> F[Video Generation]
    F --> G[Output Video]
```

### Pipeline Steps

1. **Frame Extraction**: Intelligently samples key frames from the input video
2. **Prompt Enhancement**: Uses AI to refine and improve transformation prompts
3. **Image Generation**: Creates transformed images using Gemini Vision
4. **Video Analysis**: Analyzes the video for context and continuity
5. **Video Generation**: Produces the final transformed video

## ğŸ”’ Security

- Never commit `.env` files with API keys
- Use environment variables in production
- Implement rate limiting for public deployments
- Add authentication for sensitive operations
- Regularly rotate API keys

## ğŸ› Troubleshooting

### Common Issues

**Server won't start**
- Verify Python version (3.8+)
- Check all dependencies: `pip install -r requirements.txt`
- Ensure port 5001 is available

**Processing fails**
- Verify API keys in `.env`
- Check video file size (<500MB)
- Ensure valid video format (MP4, AVI, MOV, MKV)

**No output video**
- Verify EachLabs API key
- Check internet connection
- Review logs in `logs/` directory

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Google Gemini for AI vision capabilities
- EachLabs for video generation
- OpenRouter for API gateway services
- Flask community for the web framework

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

Built with â¤ï¸ using AI-powered technologies